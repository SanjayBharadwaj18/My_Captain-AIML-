{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","\n","\n","import os\n","print(os.listdir(\"C:\\Users\\Sanjay Bharadwaj U\\Desktop\\My cap\\AIML(Assignment-7)\\game_of_thrones.txt\"))\n","\n","# Any results you write to the current directory are saved as output."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"374bf57230fd87770c16551b6d82f0f3be5acec8","trusted":true},"outputs":[],"source":["# For deleting any pre-existing models\n","for filename in os.listdir():\n","    if filename.endswith('.hdf5'):\n","        os.unlink(filename)\n","os.listdir()"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[],"source":["import keras\n","from keras.models import Sequential\n","from keras.layers import LSTM, Dense, Dropout\n","from keras.callbacks import ModelCheckpoint\n","from keras.utils import np_utils\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"66ac8f4b65f37b45a132cd54c3af67f8cae72701","trusted":true},"outputs":[],"source":["SEQ_LENGTH = 100"]},{"cell_type":"markdown","metadata":{"_uuid":"74a14b6991cb4c5566b199a25a3d8f69e4c35498"},"source":["Now that we've imported everything we need form Keras, we're all set to go!\n","\n","First, we load our data."]},{"cell_type":"markdown","metadata":{"_uuid":"7c0c9448862b1febd5ea610698a6f4eed1b19ec2"},"source":["What np_utils.to_categorical does"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"fa23fff80462bef8c1a6601298b01fd9ea85c6b2","trusted":true},"outputs":[],"source":["test_x = np.array([1, 2, 0, 4, 3, 7, 10])\n","\n","# one hot encoding\n","test_y = np_utils.to_categorical(test_x)\n","print(test_x)\n","print(test_y)"]},{"cell_type":"markdown","metadata":{"_uuid":"4c083b464aa9fd5cdb97c5188715663f5e1482e0"},"source":["This functions returns an array of sequences from the input text file and the corresponding output for each sequence encoded as a one-hot vector."]},{"cell_type":"markdown","metadata":{"_uuid":"d8fac43f24e8a590d822473fcb642027a60b5d28"},"source":["Now we add a function to create our LSTM."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"e130640d4764d31640b6a51b23401423d188480a","trusted":true},"outputs":[],"source":["# Using keras functional model\n","def create_functional_model(n_layers, input_shape, hidden_dim, n_out, **kwargs):\n","    drop        = kwargs.get('drop_rate', 0.2)\n","    activ       = kwargs.get('activation', 'softmax')\n","    mode        = kwargs.get('mode', 'train')\n","    hidden_dim  = int(hidden_dim)\n","\n","    inputs      = Input(shape = (input_shape[1], input_shape[2]))\n","    model       = LSTM(hidden_dim, return_sequences = True)(inputs)\n","    model       = Dropout(drop)(model)\n","    model       = Dense(n_out)(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"2884f42980547a01c3ce4ff9616d68f774cd27d9","trusted":true},"outputs":[],"source":["# Using keras sequential model\n","def create_model(n_layers, input_shape, hidden_dim, n_out, **kwargs):\n","    drop        = kwargs.get('drop_rate', 0.2)\n","    activ       = kwargs.get('activation', 'softmax')\n","    mode        = kwargs.get('mode', 'train')\n","    hidden_dim  = int(hidden_dim)\n","    model       = Sequential()\n","    flag        = True \n","\n","    if n_layers == 1:   \n","        model.add( LSTM(hidden_dim, input_shape = (input_shape[1], input_shape[2])) )\n","        if mode == 'train':\n","            model.add( Dropout(drop) )\n","\n","    else:\n","        model.add( LSTM(hidden_dim, input_shape = (input_shape[1], input_shape[2]), return_sequences = True) )\n","        if mode == 'train':\n","            model.add( Dropout(drop) )\n","        for i in range(n_layers - 2):\n","            model.add( LSTM(hidden_dim, return_sequences = True) )\n","            if mode == 'train':\n","                model.add( Dropout(drop) )\n","        model.add( LSTM(hidden_dim) )\n","\n","    model.add( Dense(n_out, activation = activ) )\n","\n","    return model"]},{"cell_type":"markdown","metadata":{"_uuid":"493db6caa07398a1c709c98c4d1c568184d70494"},"source":["Training our model"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"badb5b0e05143d2f38f1c937d0f494207252c9df","trusted":true},"outputs":[],"source":["def train(model, X, Y, n_epochs, b_size, vocab_size, **kwargs):    \n","    loss            = kwargs.get('loss', 'categorical_crossentropy')\n","    opt             = kwargs.get('optimizer', 'adam')\n","    \n","    model.compile(loss = loss, optimizer = opt)\n","\n","    filepath        = \"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n","    checkpoint      = ModelCheckpoint(filepath, monitor = 'loss', verbose = 1, save_best_only = True, mode = 'min')\n","    callbacks_list  = [checkpoint]\n","    X               = X / float(vocab_size)\n","    model.fit(X, Y, epochs = n_epochs, batch_size = b_size, callbacks = callbacks_list)"]},{"cell_type":"markdown","metadata":{"_uuid":"df5e78349cd2326b86ab48a2c03d460987283f7d"},"source":["The fit function will run the input batchwase n_epochs number of times and it will save the weights to a file whenever there is an improvement. This is taken care of through the callback. <br><br>\n","After the training is done or once you find a loss that you are happy with, you can test how well the model generates text."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"083e06639dd146c1aa657870718ce7e62ee44e43","trusted":true},"outputs":[],"source":["def generate_text(model, X, filename, ix_to_char, vocab_size):\n","    \n","    # Load the weights from the epoch with the least loss\n","    model.load_weights(filename)\n","    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')\n","\n","    start   = np.random.randint(0, len(X) - 1)\n","    pattern = np.ravel(X[start]).tolist()\n","\n","    # We seed the model with a random sequence of 100 so it can start predicting\n","    print (\"Seed:\")\n","    print (\"\\\"\", ''.join([ix_to_char[value] for value in pattern]), \"\\\"\")\n","    output = []\n","    for i in range(250):\n","        x           = np.reshape(pattern, (1, len(pattern), 1))\n","        x           = x / float(vocab_size)\n","        prediction  = model.predict(x, verbose = 0)\n","        index       = np.argmax(prediction)\n","        result      = index\n","        output.append(result)\n","        pattern.append(index)\n","        pattern = pattern[1 : len(pattern)]\n","\n","    print(\"Predictions\")\n","    print (\"\\\"\", ''.join([ix_to_char[value] for value in output]), \"\\\"\")"]},{"cell_type":"markdown","metadata":{"_uuid":"c492e318017ea0e2b7f4cec746672097f3ee47d8"},"source":["Now we're ready to either train or test our model."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"411c2ae0e703c01f373c5573a030489f1c8aeb69","trusted":true},"outputs":[],"source":["filename    = '../input/game_of_thrones.txt'\n","data        = open(filename).read()\n","data        = data.lower()\n","# Find all the unique characters\n","chars       = sorted(list(set(data)))\n","char_to_int = dict((c, i) for i, c in enumerate(chars))\n","ix_to_char  = dict((i, c) for i, c in enumerate(chars))\n","vocab_size  = len(chars)\n","\n","print(\"List of unique characters : \\n\", chars)\n","\n","print(\"Number of unique characters : \\n\", vocab_size)\n","\n","print(\"Character to integer mapping : \\n\", char_to_int)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"01dd50fbbf08d36d9acc778ef8f1ab855eeeb12b","trusted":true},"outputs":[],"source":["list_X      = []\n","list_Y      = []\n","\n","# Python append is faster than numpy append. Try it!\n","for i in range(0, len(data) - SEQ_LENGTH, 1):\n","    seq_in  = data[i : i + SEQ_LENGTH]\n","    seq_out = data[i + SEQ_LENGTH]\n","    list_X.append([char_to_int[char] for char in seq_in])\n","    list_Y.append(char_to_int[seq_out])\n","\n","n_patterns  = len(list_X)\n","print(\"Number of sequences in data set : \\n\", n_patterns)\n","print(list_X[0])\n","print(list_X[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"26b51a7d383e70011417f4d050b2e7be1a2c1388","trusted":true},"outputs":[],"source":["X           = np.reshape(list_X, (n_patterns, SEQ_LENGTH, 1)) # (n, 100, 1)\n","# Encode output as one-hot vector\n","Y           = np_utils.to_categorical(list_Y)\n","\n","print(X[0])\n","print(Y[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"28aafb8fec068e9979dd9d35244b026eed1cb987","trusted":true},"outputs":[],"source":["print(\"Shape of input data \", X.shape, \"\\nShape of output data \", Y.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"b726be59c2858819e3e9ae23576206db8122d90c","trusted":true},"outputs":[],"source":["model   = create_model(1, X.shape, 256, Y.shape[1], mode = 'train')"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"26bdbaee4235f5d035efd3dce0da6e639cd2ce66","trusted":true},"outputs":[],"source":["train(model, X[:1024], Y[:1024], 2, 512, vocab_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"708eb95f9f22cd304877580d9f8d9c54c2b28062","trusted":true},"outputs":[],"source":["# Iterating through each model and generating text\n","for filename in os.listdir():\n","    if filename.endswith('.hdf5'):\n","        print(\"Model Name:\", filename)\n","        generate_text(model, X, filename, ix_to_char, vocab_size)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":76821,"sourceId":172291,"sourceType":"datasetVersion"}],"dockerImageVersionId":12836,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":4}
